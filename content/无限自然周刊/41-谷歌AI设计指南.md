---
slug: 041-google-ai-design-guide
datetime: 2024-08-25 21:07
summary: 谷歌和微软的AI交互设计指南强调透明度、用户控制、伦理和包容性，帮助设计师创建人性化、高效的AI系统，通过引导用户、处理不确定性、建立信任及持续改进提升用户体验。
tags:
  - AI设计
  - 用户体验
  - 伦理考量
cover_image_url: ""
dg-publish: true
---
>Hi，新的一周（2%）即将到来，《Link设计周刊》长期关注ToB/G、Iot、SaaS行业产品体验设计，关注成长，关注优质信息源，更关注如何更好的生活。好的内容值得被分享~

![[images/Pasted image 20240825193712.png]]

----------
# 🍉谷歌AI交互设计指南

谷歌的 《People + AI Guidebook》 是一份指导设计人员如何创建与人工智能（AI）系统进行有效交互的指南。这本指南是谷歌与 UX 设计师、AI 研究人员和工程师合作开发的，旨在帮助设计团队了解如何在产品中有效地集成 AI，并确保用户体验的优化。

以下是该指南中的关键内容和交互指南的详细介绍：

### 1. **明确 AI 系统的能力和局限性**

- **设定期望**：设计师需要明确告知用户 AI 系统能做什么以及不能做什么。通过设定正确的期望，用户会对系统的输出有一个合理的期望值，从而避免失望或误解。
- **透明度**：确保系统的运作是透明的，用户能够理解 AI 的工作方式及其背后的逻辑。

### 2. **引导用户提供合适的输入**

- **教育用户**：AI 系统的性能往往取决于用户输入的质量。设计师应引导用户如何正确使用系统，例如提供清晰的输入示例或输入格式要求。
- **实时反馈**：在用户输入过程中提供反馈，以便用户可以及时调整他们的输入，增加 AI 的响应准确性。

### 3. **处理不确定性**

- **表明不确定性**：当 AI 系统对某个任务不确定时，应该明确告诉用户，而不是给出一个确定的答案。这可以通过使用模糊的语言、置信度评分或多个建议选项来实现。
- **允许用户控制**：用户应该能够控制 AI 的决策，例如通过提供纠错机制或允许用户选择不同的选项。

### 4. **设计回馈环路**

- **学习机制**：设计能够让 AI 学习和改进的回馈环路，允许用户在交互过程中提供反馈，并使用这些反馈来调整 AI 的行为。
- **回顾机制**：提供一个系统回顾的机制，允许用户查看系统的决策过程，了解为什么 AI 会得出某个结论，并根据需要调整。

### 5. **确保人性化和伦理考量**

- **伦理设计**：考虑 AI 系统可能对社会产生的影响，确保设计符合伦理标准，避免偏见或歧视。
- **包容性**：设计时考虑到多样化的用户群体，确保系统对于不同背景、能力和需求的用户都具有包容性。

### 6. **提升信任与安全感**

- **建立信任**：通过一致性、可预测性和透明性来建立用户对系统的信任。
- **安全设计**：确保系统设计的安全性，防止用户的隐私被侵犯或数据被误用。

### 7. **持续改进与适应**

- **迭代设计**：AI 系统应该随着用户的使用和反馈进行不断地迭代和优化，以更好地适应用户的需求和期望。
- **用户参与**：设计过程中应持续地与用户互动，确保系统的演变符合用户的实际需求。

### 8. **理解用户需求与情境**

- **情境感知**：AI 系统应当理解用户所处的情境，并根据情境提供相应的服务。例如，在不同的环境下提供不同的提示或建议。
- **个性化**：根据用户的历史行为和偏好，个性化系统的交互和响应。

通过这些交互指南，设计师可以创建更为智能和人性化的 AI 产品，从而提升用户体验和满意度。该指南强调了透明度、信任、用户控制和持续学习的重要性，同时也考虑了伦理和包容性在 AI 系统中的应用。

https://pair.withgoogle.com/guidebook/patterns/how-do-i-get-started

偷懒问了ChatGPT，建议还是阅读原文，配合一些案例，更利于理解吸收。


# 🍉微软AI交互设计指南

微软的 AI 交互设计指南（AI Design Guidelines）也为设计师提供了构建人性化、可访问和有效的人工智能系统的指导原则。与谷歌的 People + AI Guidebook 相比，微软的指南同样重视透明性、伦理和用户体验，但在一些细节和侧重点上有所不同。以下是微软 AI 交互设计指南的主要内容及其与谷歌指南的区别：

### 微软 AI 交互设计指南的核心原则

1. **尊重用户的控制权**
    
    - **赋予用户权力**：用户应始终保持对 AI 系统的控制权。设计师需要确保 AI 不会在未经用户同意的情况下采取行动，并为用户提供多种选择以决定如何使用系统的建议或自动化功能。
    - **透明的用户选择**：在设计中，应当明确 AI 的决策和行为，确保用户能够理解系统是如何做出决定的，并有机会干预或调整这些决定。
2. **优先考虑透明度**
    
    - **解释性 AI**：AI 系统应能解释其决策过程。通过提供可理解的理由和证据，让用户了解系统是如何得出结论的，这对于建立信任至关重要。
    - **明示数据来源**：告知用户系统使用了哪些数据以及这些数据是如何影响决策的，使得 AI 的行为更加透明和可信。
3. **注重公平性和包容性**
    
    - **公平的算法**：确保 AI 系统的设计和数据使用是公平的，不会因为性别、种族、年龄或其他因素对某些群体产生偏见。设计师应审查和测试系统，以识别并修正潜在的偏见。
    - **多样性考虑**：在设计过程中，考虑到来自不同背景和需求的用户，确保系统对各种用户群体都能友好和有效地服务。
4. **确保隐私和安全**
    
    - **数据隐私**：在系统设计中要优先考虑用户的隐私，确保用户的数据在收集、存储和使用过程中都得到了适当的保护。明确告知用户他们的数据将如何被使用，并为他们提供控制数据的工具。
    - **安全性设计**：AI 系统应当具备强大的安全措施，防止数据泄露或恶意利用。
5. **提升信任感**
    
    - **一致性与可靠性**：通过提供一致的行为和可预测的结果来建立用户对 AI 系统的信任。系统应在不同情境下表现一致，不会出现不可解释的行为。
    - **回报信任**：AI 系统应通过用户反馈不断改进，并向用户展示这些改进如何提升了系统的表现。
6. **同理心与情感设计**
    
    - **理解用户情感**：AI 系统应能够识别并响应用户的情感状态。例如，在用户表现出困惑或沮丧时，系统可以提供额外的支持或调整响应方式。
    - **人性化互动**：AI 应该设计得更加人性化，能够在适当的时候展现幽默感、同理心或其他情感特征，以改善用户体验。
7. **持续学习与改进**
    
    - **用户反馈机制**：设计有效的反馈机制，确保用户能够轻松地向系统提供反馈，并使 AI 能够利用这些反馈进行持续改进。
    - **动态适应**：AI 系统应随着时间的推移不断学习和适应用户的行为、偏好和环境变化。

https://learn.microsoft.com/en-us/azure/ai-services/responsible-use-of-ai-overview
https://zhuanlan.zhihu.com/p/387277603


# 📮About Me

做一个长期主义者，对优质内容拥有足够的好奇心，探寻内心的深处，持续向前。

- [语雀↘︎](https://www.yuque.com/zing123)：我的数字花园
- [Newsletter-Link设计周刊↘︎](https://zjing.zhubai.love/)：分享精读文章和有意思的工具
- [知识库-信息启示录↘︎](https://flowus.cn/zing/share/aa202f8a-14a7-4429-a5a8-2b459a4de181?code=U4N4HU)：缩短你与优质信息的距离
- [Blog↘︎](https://quail.ink/zing927)：quail
- [bento.me↘︎](https://bento.me/zing)：电子名片

